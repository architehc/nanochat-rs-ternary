//! Cross-validation: compare pre-generated reference outputs with Rust model.
//!
//! Uses reference data in `training/` (ref.gguf, ref.mhc, ref_logits.npy).
//! These were generated by a previous Python training pipeline.
//!
//! To run this test:
//!   cargo test cross_validate -- --ignored

use std::path::Path;

/// Load a .npy f32 array (simple NumPy v1/v2 format parser).
///
/// Supports only 1-D float32 little-endian arrays, which is what
/// `np.save(path, array)` produces for our reference logits.
fn load_npy_f32(path: &str) -> Vec<f32> {
    let data = std::fs::read(path).expect("failed to read .npy file");

    // NumPy .npy format:
    // Bytes 0..6:   magic "\x93NUMPY"
    // Byte  6:      major version
    // Byte  7:      minor version
    // Bytes 8..10:  header_len (u16 LE for v1) or 8..12 (u32 LE for v2)
    // Header:       ASCII dict with 'descr', 'fortran_order', 'shape'
    // Data:         raw binary tensor data

    assert!(
        data.len() >= 10,
        ".npy file too small: {} bytes",
        data.len()
    );
    assert_eq!(&data[..6], b"\x93NUMPY", "not a .npy file (bad magic)");

    let major = data[6];
    let header_len = if major == 1 {
        u16::from_le_bytes([data[8], data[9]]) as usize
    } else {
        // v2 or v3: 4-byte header length
        assert!(
            data.len() >= 12,
            ".npy v2 file too small: {} bytes",
            data.len()
        );
        u32::from_le_bytes([data[8], data[9], data[10], data[11]]) as usize
    };

    let data_start = if major == 1 {
        10 + header_len
    } else {
        12 + header_len
    };

    assert!(
        data_start <= data.len(),
        "data_start {} exceeds file size {}",
        data_start,
        data.len()
    );

    // Verify it looks like float32 data (header should contain '<f4' or 'float32')
    let header_bytes = if major == 1 {
        &data[10..10 + header_len]
    } else {
        &data[12..12 + header_len]
    };
    let header_str = String::from_utf8_lossy(header_bytes);
    assert!(
        header_str.contains("<f4") || header_str.contains("float32"),
        "expected float32 dtype in .npy header, got: {}",
        header_str.trim()
    );

    // Parse raw data as f32 little-endian
    let raw = &data[data_start..];
    assert!(
        raw.len().is_multiple_of(4),
        "data section length {} not a multiple of 4",
        raw.len()
    );

    raw.chunks_exact(4)
        .map(|c| f32::from_le_bytes([c[0], c[1], c[2], c[3]]))
        .collect()
}

#[test]
#[ignore] // Requires reference files (ref.gguf, ref.mhc, ref_logits.npy) that are gitignored
fn cross_validate_python_rust() {
    let manifest_dir = env!("CARGO_MANIFEST_DIR");
    let ref_dir = format!("{}/training", manifest_dir);

    let gguf_path = format!("{}/ref.gguf", ref_dir);
    let mhc_path = format!("{}/ref.mhc", ref_dir);
    let npy_path = format!("{}/ref_logits.npy", ref_dir);

    assert!(
        Path::new(&gguf_path).exists()
            && Path::new(&mhc_path).exists()
            && Path::new(&npy_path).exists(),
        "cross_validate requires reference files in {} (expected ref.gguf, ref.mhc, ref_logits.npy). \
         Run `cd training && python gen_reference.py` before running tests.",
        ref_dir
    );

    // Load reference logits from Python
    let ref_logits = load_npy_f32(&npy_path);
    println!(
        "Loaded Python reference logits: {} values, range [{:.6}, {:.6}]",
        ref_logits.len(),
        ref_logits.iter().cloned().fold(f32::INFINITY, f32::min),
        ref_logits.iter().cloned().fold(f32::NEG_INFINITY, f32::max),
    );

    // Load model in Rust from exported GGUF + mHC
    let mut model = nanochat_model::model::NanochatModel::from_gguf(&gguf_path, &mhc_path)
        .expect("failed to load GGUF + mHC model");

    // Verify mHC matrices are doubly stochastic
    model
        .verify_mhc()
        .expect("mHC verification failed on loaded model");

    // Run the same input sequence as Python: [1, 5, 10, 20, 42]
    let tokens: Vec<u32> = vec![1, 5, 10, 20, 42];
    let rust_logits = model.forward_sequence(&tokens);

    println!(
        "Rust model logits: {} values, range [{:.6}, {:.6}]",
        rust_logits.len(),
        rust_logits.iter().cloned().fold(f32::INFINITY, f32::min),
        rust_logits
            .iter()
            .cloned()
            .fold(f32::NEG_INFINITY, f32::max),
    );

    // Verify sizes match
    assert_eq!(
        rust_logits.len(),
        ref_logits.len(),
        "logit vector size mismatch: Rust={} vs Python={}",
        rust_logits.len(),
        ref_logits.len()
    );

    // Compare element-wise
    let max_diff: f32 = rust_logits
        .iter()
        .zip(ref_logits.iter())
        .map(|(a, b)| (a - b).abs())
        .fold(0.0f32, f32::max);

    let mean_diff: f32 = rust_logits
        .iter()
        .zip(ref_logits.iter())
        .map(|(a, b)| (a - b).abs())
        .sum::<f32>()
        / rust_logits.len() as f32;

    // Find the index of the maximum difference for debugging
    let (worst_idx, _) = rust_logits
        .iter()
        .zip(ref_logits.iter())
        .enumerate()
        .map(|(i, (a, b))| (i, (a - b).abs()))
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap())
        .unwrap();

    println!("\nCross-validation results:");
    println!("  max_diff:  {:.6}", max_diff);
    println!("  mean_diff: {:.6}", mean_diff);
    println!(
        "  worst idx: {} (Rust={:.6}, Python={:.6})",
        worst_idx, rust_logits[worst_idx], ref_logits[worst_idx]
    );

    // Threshold: 1e-2
    // Note: differences arise from several sources that compound across layers:
    //   - STE quantization path in Python vs direct ternary packing in Rust
    //   - Float accumulation order (row-major in Python vs column-major in Rust)
    //   - RoPE computation precision differences
    //   - Attention softmax numerical differences
    // For a single GEMV the tolerance is ~1e-4, but a full multi-layer model
    // with attention and FFN compounds these differences. Empirically, a 2-layer
    // model with dim=128 shows max_diff around 0.005-0.01.
    let threshold = 1e-2;
    assert!(
        max_diff < threshold,
        "Python-Rust cross-validation FAILED: max_diff={:.6} (threshold {}) at index {}",
        max_diff,
        threshold,
        worst_idx
    );

    println!(
        "\nCross-validation PASSED: max_diff={:.6} < {}",
        max_diff, threshold
    );
}
