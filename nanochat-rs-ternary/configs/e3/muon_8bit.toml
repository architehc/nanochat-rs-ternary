# E3: 8-bit Muon optimizer
# Expected gain: 86% memory reduction

[model]
name = "e3-muon-8bit"
vocab_size = 32000
hidden_dim = 1024
num_layers = 12
num_heads = 12
num_kv_heads = 4
ffn_mult = 3.5
max_seq_len = 2048
group_size = 128
mhc_n_streams = 2

[training]
total_steps = 10000
batch_size = 16
seq_length = 2048
learning_rate = 0.02
warmup_steps = 1000
weight_decay = 0.01
grad_clip = 1.0
entropy_weight = 0.01

# E3 features
use_mtp = true
mtp_n_tokens = 4
mtp_weight = 0.2
use_collider = true
collider_threshold = 0.3
collider_sparsity = 0.35
use_async_loader = true
num_workers = 4
prefetch_batches = 8

# 8-bit quantized optimizer
optimizer_type = "muon"
muon_momentum = 0.95
use_8bit_optim = true
use_galore = false

schedule_type = "wsd"
stable_ratio = 0.8
min_lr_ratio = 0.1

[hardware]
target = "single_gpu"
fp16 = true
gradient_checkpointing = false
